"""
Dataset preparation: Randomize folders and create train/val/test splits
Author: Kishor-04
Date: 2025-01-06
UPDATED: Physically move folders to train/val/test structure
"""

import yaml
import pickle
from pathlib import Path
import random
import shutil
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from datetime import datetime

def randomize_folder_names(faces_dir):
    """
    Rename all video folders to random numbers to prevent ordering bias
    This ensures videos from same source (e.g., Celeb-DF) are not grouped together
    """
    faces_dir = Path(faces_dir)
    
    print("\n🔀 Randomizing folder names to prevent ordering bias...")
    
    for label in ['real', 'fake']:
        label_dir = faces_dir / label
        
        if not label_dir.exists():
            print(f"  ⚠️  {label} directory not found, skipping...")
            continue
        
        # Get all existing video folders
        video_dirs = [d for d in label_dir.iterdir() if d.is_dir()]
        
        if not video_dirs:
            print(f"  ⚠️  No video folders found in {label}, skipping...")
            continue
        
        # Check if already randomized (all folders are numeric)
        already_randomized = all(d.name.isdigit() for d in video_dirs)
        
        if already_randomized:
            print(f"  ✓ {label.capitalize()} folders already randomized ({len(video_dirs)} videos)")
            continue
        
        print(f"  🔄 Renaming {len(video_dirs)} {label} video folders...")
        
        # Create temporary directory for renaming
        temp_dir = label_dir.parent / f'temp_{label}_rename'
        temp_dir.mkdir(exist_ok=True)
        
        # Generate random order
        random_indices = list(range(len(video_dirs)))
        random.shuffle(random_indices)
        
        # Move to temp with random names
        mapping = {}
        for new_idx, old_dir in enumerate(tqdm(video_dirs, desc=f"    {label}")):
            new_name = str(random_indices[new_idx])
            new_path = temp_dir / new_name
            
            try:
                shutil.move(str(old_dir), str(new_path))
                mapping[old_dir.name] = new_name
            except Exception as e:
                print(f"\n    ⚠️  Error moving {old_dir.name}: {e}")
        
        # Remove old directory and rename temp
        try:
            if label_dir.exists() and not any(label_dir.iterdir()):
                label_dir.rmdir()
        except:
            pass
        
        shutil.move(str(temp_dir), str(label_dir))
        
        print(f"  ✓ Renamed {len(mapping)} {label} folders to random numbers")
        
        # Save mapping with UTF-8 encoding
        mapping_file = faces_dir / f'{label}_folder_mapping.txt'
        try:
            with open(mapping_file, 'w', encoding='utf-8') as f:
                f.write("# Original folder name -> Random number\n")
                f.write("# Generated by Video Deepfake Detection - Model A\n")
                f.write("# Author: Kishor-04\n")
                f.write(f"# Date: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\n")
                f.write(f"# Total mappings: {len(mapping)}\n")
                f.write("#" + "="*60 + "\n\n")
                for old_name, new_name in sorted(mapping.items(), key=lambda x: int(x[1])):
                    f.write(f"{old_name} -> {new_name}\n")
            
            print(f"  💾 Mapping saved: {mapping_file}")
        except Exception as e:
            print(f"  ⚠️  Warning: Could not save mapping with UTF-8: {e}")
    
    print("✅ Folder randomization completed!\n")

def move_folders_to_splits(faces_dir, config):
    """
    Move video folders from faces/real and faces/fake to train/val/test structure
    """
    faces_dir = Path(faces_dir)
    
    # Check if already organized
    train_dir = faces_dir / 'train'
    if train_dir.exists() and (train_dir / 'real').exists():
        print("\n✓ Folders already organized in train/val/test structure")
        return load_existing_structure(faces_dir)
    
    print("\n📁 Organizing folders into train/val/test structure...")
    
    # Collect all video folders
    videos_data = {'real': [], 'fake': []}
    
    for label in ['real', 'fake']:
        label_dir = faces_dir / label
        if label_dir.exists():
            for video_dir in sorted(label_dir.iterdir(), key=lambda x: int(x.name) if x.name.isdigit() else x.name):
                if video_dir.is_dir():
                    frame_paths = list(video_dir.glob("*.jpg"))
                    if frame_paths:
                        videos_data[label].append((video_dir.name, video_dir, len(frame_paths)))
    
    # Count statistics
    total_real = len(videos_data['real'])
    total_fake = len(videos_data['fake'])
    total_real_frames = sum(f for _, _, f in videos_data['real'])
    total_fake_frames = sum(f for _, _, f in videos_data['fake'])
    
    print(f"\n📊 Dataset Statistics:")
    print(f"  Real videos: {total_real} ({total_real_frames:,} frames)")
    print(f"  Fake videos: {total_fake} ({total_fake_frames:,} frames)")
    print(f"  Total: {total_real + total_fake} videos, {total_real_frames + total_fake_frames:,} frames")
    
    # Split ratios
    train_ratio = config['dataset']['train_ratio']
    val_ratio = config['dataset']['val_ratio']
    test_ratio = config['dataset']['test_ratio']
    
    # Split real videos
    real_videos = videos_data['real']
    real_train, real_temp = train_test_split(real_videos, test_size=(val_ratio + test_ratio), random_state=42)
    val_size = val_ratio / (val_ratio + test_ratio)
    real_val, real_test = train_test_split(real_temp, test_size=(1 - val_size), random_state=42)
    
    # Split fake videos
    fake_videos = videos_data['fake']
    fake_train, fake_temp = train_test_split(fake_videos, test_size=(val_ratio + test_ratio), random_state=42)
    fake_val, fake_test = train_test_split(fake_temp, test_size=(1 - val_size), random_state=42)
    
    splits_assignment = {
        'train': {'real': real_train, 'fake': fake_train},
        'val': {'real': real_val, 'fake': fake_val},
        'test': {'real': real_test, 'fake': fake_test}
    }
    
    print(f"\n📋 Data Splits (Video-Level):")
    print(f"  Train: {len(real_train)} real + {len(fake_train)} fake = {len(real_train) + len(fake_train)} videos")
    print(f"  Val:   {len(real_val)} real + {len(fake_val)} fake = {len(real_val) + len(fake_val)} videos")
    print(f"  Test:  {len(real_test)} real + {len(fake_test)} fake = {len(real_test) + len(fake_test)} videos")
    
    # Create new directory structure
    print(f"\n🔄 Moving folders to train/val/test structure...")
    
    # Mapping for text files
    split_mappings = {'real': [], 'fake': []}
    
    for split_name, split_data in splits_assignment.items():
        for label, video_list in split_data.items():
            # Create destination directory
            dest_dir = faces_dir / split_name / label
            dest_dir.mkdir(parents=True, exist_ok=True)
            
            # Move each video folder
            for video_name, video_path, num_frames in tqdm(video_list, desc=f"  {split_name}/{label}", ncols=80):
                dest_path = dest_dir / video_name
                
                if not dest_path.exists():
                    try:
                        shutil.move(str(video_path), str(dest_path))
                    except Exception as e:
                        print(f"\n  ⚠️  Error moving {video_path}: {e}")
                
                # Record mapping
                split_mappings[label].append({
                    'folder': video_name,
                    'split': split_name,
                    'num_frames': num_frames
                })
    
    # Remove old real/ and fake/ directories if empty
    for label in ['real', 'fake']:
        old_dir = faces_dir / label
        if old_dir.exists() and not any(old_dir.iterdir()):
            try:
                old_dir.rmdir()
                print(f"  ✓ Removed empty directory: {label}/")
            except:
                pass
    
    print(f"✅ Folder organization completed!")
    
    return split_mappings

def save_split_mappings(split_mappings, faces_dir):
    """
    Save mappings of which folders went to which split
    Creates real_split_mapping.txt and fake_split_mapping.txt
    """
    print(f"\n📝 Creating split mapping files...")
    
    # Load original name mappings
    original_mappings = {}
    for label in ['real', 'fake']:
        original_mappings[label] = {}
        mapping_file = faces_dir / f'{label}_folder_mapping.txt'
        
        if mapping_file.exists():
            try:
                with open(mapping_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip() and not line.startswith('#'):
                            parts = line.strip().split(' -> ')
                            if len(parts) == 2:
                                original_mappings[label][parts[1]] = parts[0]
            except:
                pass
    
    # Create mapping files for each label
    for label in ['real', 'fake']:
        mapping_file = faces_dir / f'{label}_split_mapping.txt'
        
        try:
            with open(mapping_file, 'w', encoding='utf-8') as f:
                f.write("="*70 + "\n")
                f.write(f"{label.upper()} VIDEOS - TRAIN/VAL/TEST SPLIT MAPPING\n")
                f.write("="*70 + "\n")
                f.write("# Generated by Video Deepfake Detection - Model A\n")
                f.write("# Author: Kishor-04\n")
                f.write(f"# User: Kishor-04\n")
                f.write(f"# Date: 2025-01-06 07:21:18 UTC\n")
                f.write("="*70 + "\n\n")
                f.write("Format: [Split] [Folder] [Original_Name] [Num_Frames]\n\n")
                
                # Group by split
                by_split = {'train': [], 'val': [], 'test': []}
                for item in split_mappings[label]:
                    by_split[item['split']].append(item)
                
                # Write each split
                for split_name in ['train', 'val', 'test']:
                    f.write("\n" + "-"*70 + "\n")
                    f.write(f"{split_name.upper()} SET ({len(by_split[split_name])} videos)\n")
                    f.write("-"*70 + "\n\n")
                    
                    for item in sorted(by_split[split_name], key=lambda x: int(x['folder'])):
                        folder = item['folder']
                        num_frames = item['num_frames']
                        original_name = original_mappings[label].get(folder, 'Unknown')
                        f.write(f"[{split_name.upper():5}] [{folder:>4}] -> {original_name:<50} ({num_frames:>3} frames)\n")
                    
                    total_frames = sum(item['num_frames'] for item in by_split[split_name])
                    f.write(f"\nTotal: {len(by_split[split_name])} videos, {total_frames:,} frames\n")
                
                # Overall summary
                f.write("\n" + "="*70 + "\n")
                f.write("SUMMARY\n")
                f.write("="*70 + "\n\n")
                for split_name in ['train', 'val', 'test']:
                    total = len(by_split[split_name])
                    frames = sum(item['num_frames'] for item in by_split[split_name])
                    f.write(f"{split_name.capitalize():5} -> {total:>4} videos, {frames:>6,} frames\n")
            
            print(f"  ✓ Saved: {mapping_file}")
        
        except Exception as e:
            print(f"  ⚠️  Warning: Could not save {label} mapping: {e}")

def load_existing_structure(faces_dir):
    """
    Load video information from existing train/val/test structure
    """
    split_mappings = {'real': [], 'fake': []}
    
    for split_name in ['train', 'val', 'test']:
        for label in ['real', 'fake']:
            split_label_dir = faces_dir / split_name / label
            
            if split_label_dir.exists():
                for video_dir in split_label_dir.iterdir():
                    if video_dir.is_dir():
                        num_frames = len(list(video_dir.glob("*.jpg")))
                        if num_frames > 0:
                            split_mappings[label].append({
                                'folder': video_dir.name,
                                'split': split_name,
                                'num_frames': num_frames
                            })
    
    return split_mappings

def create_data_splits_info(faces_dir):
    """
    Create splits info from the organized folder structure
    """
    splits = {'train': ([], []), 'val': ([], []), 'test': ([], [])}
    
    for split_name in ['train', 'val', 'test']:
        paths = []
        labels = []
        
        # Real images (label = 0)
        real_dir = faces_dir / split_name / 'real'
        if real_dir.exists():
            for video_dir in real_dir.iterdir():
                if video_dir.is_dir():
                    for img_path in video_dir.glob("*.jpg"):
                        paths.append(str(img_path))
                        labels.append(0)
        
        # Fake images (label = 1)
        fake_dir = faces_dir / split_name / 'fake'
        if fake_dir.exists():
            for video_dir in fake_dir.iterdir():
                if video_dir.is_dir():
                    for img_path in video_dir.glob("*.jpg"):
                        paths.append(str(img_path))
                        labels.append(1)
        
        splits[split_name] = (paths, labels)
    
    return splits

def prepare_and_save_splits(config_path='config.yaml'):
    """
    Main function: Randomize folders, organize into train/val/test, and save splits
    """
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    faces_dir = Path(config['dataset']['processed_data_path']) / 'faces'
    
    if not faces_dir.exists():
        raise FileNotFoundError(f"Faces directory not found: {faces_dir}")
    
    print("\n" + "="*70)
    print("📦 DATASET PREPARATION")
    print("="*70)
    
    # Step 1: Randomize folder names (if needed)
    randomize_folder_names(faces_dir)
    
    # Step 2: Move folders to train/val/test structure
    split_mappings = move_folders_to_splits(faces_dir, config)
    
    # Step 3: Save split mappings
    save_split_mappings(split_mappings, faces_dir)
    
    # Step 4: Create and save splits info
    splits = create_data_splits_info(faces_dir)
    
    splits_dir = Path(config['dataset']['processed_data_path']) / 'splits'
    splits_dir.mkdir(exist_ok=True, parents=True)
    
    splits_file = splits_dir / 'data_splits.pkl'
    
    print(f"\n💾 Saving splits to: {splits_file}")
    with open(splits_file, 'wb') as f:
        pickle.dump(splits, f)
    
    print(f"  ✓ Saved train split: {len(splits['train'][0]):,} frames")
    print(f"  ✓ Saved val split:   {len(splits['val'][0]):,} frames")
    print(f"  ✓ Saved test split:  {len(splits['test'][0]):,} frames")
    
    # Step 5: Save summary
    summary_file = splits_dir / 'split_summary.txt'
    try:
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("Dataset Split Summary\n")
            f.write("="*70 + "\n")
            f.write("# Generated by Video Deepfake Detection - Model A\n")
            f.write("# Author: Kishor-04\n")
            f.write("# Date: 2025-01-06 07:21:18 UTC\n")
            f.write("="*70 + "\n\n")
            f.write(f"Train: {len(splits['train'][0]):,} frames\n")
            f.write(f"Val:   {len(splits['val'][0]):,} frames\n")
            f.write(f"Test:  {len(splits['test'][0]):,} frames\n")
            f.write(f"Total: {len(splits['train'][0]) + len(splits['val'][0]) + len(splits['test'][0]):,} frames\n")
        print(f"  ✓ Saved summary: {summary_file}")
    except:
        pass
    
    print(f"\n✅ Dataset preparation completed!")
    print(f"\n📂 New folder structure:")
    print(f"   data/processed/faces/")
    print(f"   ├── train/")
    print(f"   │   ├── real/ (folders moved here)")
    print(f"   │   └── fake/ (folders moved here)")
    print(f"   ├── val/")
    print(f"   │   ├── real/")
    print(f"   │   └── fake/")
    print(f"   └── test/")
    print(f"       ├── real/")
    print(f"       └── fake/")
    print(f"\n📝 Mapping files:")
    print(f"   - {faces_dir / 'real_split_mapping.txt'}")
    print(f"   - {faces_dir / 'fake_split_mapping.txt'}")
    print(f"\n💡 Next step: Run training with 'python main.py --mode train'\n")

if __name__ == "__main__":
    prepare_and_save_splits()